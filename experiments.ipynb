{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from itertools import product\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import shelve\n",
    "import tqdm\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "from tdc.benchmark_group import admet_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from huggingmolecules import MatConfig, MatFeaturizer, MatModel\n",
    "from huggingmolecules import GroverConfig, GroverFeaturizer, GroverModel\n",
    "from huggingmolecules import RMatConfig, RMatFeaturizer, RMatModel\n",
    "from models import StrippedMatModel, StrippedGroverModel, StrippedRMatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to import pysam. Please make sure it is installed.\n",
      "Error: Unable to import pysam. Please make sure it is installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from utils import *\n",
    "from datasets import *\n",
    "from predict_procedure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mat import MolecularAttentionTransformer\n",
    "\n",
    "# model = MolecularAttentionTransformer()\n",
    "# model.predict([\"CN1CC[C@]23C(=O)C[C@@H]4C(=CCO[C@H]5CC(=O)N(c6ccccc62)[C@@H]3[C@@H]54)C1\"]) ## tooks 11m 4s (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group = admet_group(path = 'data/')\n",
    "# benchmark = group.get(\"CYP2D6_Substrate_CarbonMangels\")\n",
    "\n",
    "# dataset = benchmark[\"test\"]\n",
    "\n",
    "# print(dataset[dataset.Drug == \"CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C\"].to_markdown())\n",
    "\n",
    "# Output:\n",
    "# |     | smiles                             |   Y |\n",
    "# |----:|:-----------------------------------|----:|\n",
    "# |  58 | CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C |   1 |\n",
    "# | 226 | CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C |   0 |else 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "\n",
    "# calculated = set(map(str, pathlib.Path(\"embeddings/\").glob(\"*/*.zip\")))\n",
    "\n",
    "# pairs = product(get_dataset_names(), get_embedder_names())\n",
    "\n",
    "# with open(\"embedding_params.txt\", \"w\") as f:\n",
    "#     for dataset_name, model_name in pairs:\n",
    "#         if f\"embeddings/{dataset_name}/{model_name}.zip\" not in calculated:\n",
    "#             print(dataset_name, model_name, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "group = admet_group(path='data/')\n",
    "benchmark = group.get(\"CYP2C9_Substrate_CarbonMangels\")\n",
    "\n",
    "predictions = {}\n",
    "name = benchmark['name']\n",
    "a = benchmark[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "done = set(map(str, pathlib.Path(\"results/\").glob(\"*.pkl\")))\n",
    "\n",
    "pairs = list(product(get_classification_names(), get_embedder_names()))\n",
    "calculated = list(map(lambda s: tuple(str(s).replace(\".\", \"/\").split(\"/\")[1:-1]), pathlib.Path(\"embeddings/\").glob(\"*/*.zip\")))\n",
    "\n",
    "params = list(product(list(set(pairs) & set(calculated)), [\"ridge\",\"forest\"]))\n",
    "\n",
    "\n",
    "with open(\"predict_params.txt\", \"w\") as f:\n",
    "    for (dataset_name, model_name), head_model in params:\n",
    "        if f\"results/{dataset_name}_{model_name}_{head_model}.pkl\" not in done:\n",
    "            print(dataset_name, model_name, head_model, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "done = set(map(str, pathlib.Path(\"results/\").glob(\"*.pkl\")))\n",
    "\n",
    "pairs = list(product(get_dataset_names(), get_embedder_names()))\n",
    "calculated = list(map(lambda s: tuple(str(s).replace(\".\", \"/\").split(\"/\")[1:-1]), pathlib.Path(\"embeddings/\").glob(\"*/*.zip\")))\n",
    "\n",
    "params = list(product(list(set(pairs) & set(calculated)), [\"ridge\",\"forest\"]))\n",
    "\n",
    "\n",
    "with open(\"predict_params.txt\", \"w\") as f:\n",
    "    for (dataset_name, model_name), head_model in params:\n",
    "        if f\"results/{dataset_name}_{model_name}_{head_model}.pkl\" in done and dataset_name in get_classification_names():\n",
    "            print(dataset_name, model_name, head_model, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV, RidgeCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Found local copy...\n",
      "Found local copy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('pr-auc', 0.451)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name, base_model, head_model = \"CYP2C9_Substrate_CarbonMangels\", \"ChemBERTa-10M-MTR\", \"forest\"\n",
    "\n",
    "_, split_idx = get_dataset(dataset_name)\n",
    "df = pd.read_pickle(f\"embeddings/{dataset_name}/{base_model}.zip\").drop(\"features\", axis=1, errors=\"ignore\")\n",
    "df\n",
    "\n",
    "predict_fun = get_predict_fun(dataset_name, head_model)\n",
    "\n",
    "scoring, predict_proba = get_metric(dataset_name)\n",
    "\n",
    "preds = predict_fun(df, split_idx, scoring=scoring, predict_proba=predict_proba)\n",
    "preds\n",
    "\n",
    "evaluate(dataset_name, preds)\n",
    "\n",
    "# procedure(dataset_name, base_model, head_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('pr-auc', 0.291)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(dataset_name, sigmoid(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42161421, 0.44094688, 0.42674479, 0.52222318, 0.44242793,\n",
       "       0.39327176, 0.46599716, 0.49025719, 0.45238108, 0.39434831,\n",
       "       0.44407448, 0.43001179, 0.4744063 , 0.50158968, 0.41972731,\n",
       "       0.47448883, 0.41253184, 0.4187567 , 0.4239842 , 0.43290081,\n",
       "       0.50124254, 0.46611831, 0.4480864 , 0.43627427, 0.46080884,\n",
       "       0.41171397, 0.48890338, 0.47207135, 0.4467991 , 0.41330773,\n",
       "       0.45965931, 0.41552689, 0.47110107, 0.41650123, 0.45910426,\n",
       "       0.421469  , 0.38674862, 0.41238064, 0.44726588, 0.43835653,\n",
       "       0.42135996, 0.40725152, 0.50177111, 0.50876111, 0.46087121,\n",
       "       0.40818538, 0.40765447, 0.42827417, 0.42569647, 0.42939636,\n",
       "       0.45338923, 0.47562187, 0.40627918, 0.43619709, 0.45550516,\n",
       "       0.44841165, 0.45032407, 0.48074109, 0.43216175, 0.40175156,\n",
       "       0.41086103, 0.38942793, 0.39464983, 0.49578446, 0.39557991,\n",
       "       0.39120213, 0.48614281, 0.47539514, 0.48071923, 0.48807791,\n",
       "       0.47821058, 0.47872144, 0.48521299, 0.47132218, 0.44999796,\n",
       "       0.43119883, 0.40022154, 0.45165975, 0.40268736, 0.54290555,\n",
       "       0.42272024, 0.44057524, 0.4223589 , 0.45658763, 0.41687879,\n",
       "       0.40592658, 0.45863515, 0.42670388, 0.39882034, 0.46895318,\n",
       "       0.50800839, 0.41487179, 0.45537228, 0.40426453, 0.4954225 ,\n",
       "       0.39176263, 0.48106004, 0.44553123, 0.41198193, 0.44732036,\n",
       "       0.39761956, 0.40145805, 0.3967344 , 0.39145834, 0.42674601,\n",
       "       0.42116819, 0.38055823, 0.39641131, 0.38819059, 0.38134432,\n",
       "       0.44147537, 0.44527346, 0.40027945, 0.41776404, 0.39772506,\n",
       "       0.40212475, 0.39049612, 0.3985896 , 0.5054397 , 0.4238398 ,\n",
       "       0.40452425, 0.39201299, 0.44330279, 0.50156092, 0.39956702,\n",
       "       0.40223296, 0.39302979, 0.43922136, 0.3850108 , 0.4555064 ,\n",
       "       0.43012311, 0.42334528, 0.42920015, 0.38457271, 0.41463262])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigmoid(preds - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/ogbg-molfreesolv_mat_masking_2M_forest.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tmp\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(f\"results/ogbg-molfreesolv_mat_masking_2M_forest.pkl\", \"rb\") as f:\n",
    "    tmp = pickle.load(f)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ogbg-molesol 1128\n",
      "ogbg-molfreesolv 642\n",
      "ogbg-mollipo 4200\n",
      "ogbg-molbace 1513\n",
      "ogbg-molbbbp 2039\n",
      "ogbg-molclintox 1477\n",
      "ogbg-molsider 1427\n",
      "ogbg-moltox21 7831\n",
      "ogbg-moltoxcast 8576\n",
      "ogbg-molmuv 93087\n",
      "ogbg-molhiv 41127\n",
      "Caco2_Wang 910\n",
      "Half_Life_Obach 667\n",
      "Lipophilicity_AstraZeneca 4200\n",
      "Solubility_AqSolDB 9982\n",
      "PPBR_AZ 1614\n",
      "VDss_Lombardo 1130\n",
      "Clearance_Hepatocyte_AZ 1213\n",
      "HIA_Hou 578\n",
      "Pgp_Broccatelli 1218\n",
      "Bioavailability_Ma 640\n",
      "BBB_Martins 2030\n",
      "CYP2D6_Veith 13130\n",
      "CYP3A4_Veith 12328\n",
      "CYP2C9_Veith 12092\n",
      "CYP2C9_Substrate_CarbonMangels 669\n",
      "CYP2D6_Substrate_CarbonMangels 667\n",
      "CYP3A4_Substrate_CarbonMangels 670\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in get_dataset_names():\n",
    "    df = pd.read_pickle(f\"embeddings/{dataset_name}/mol2vec.zip\")\n",
    "    print(dataset_name, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'Caco2_Wang',\n",
       " 'base_model': 'ChemBERTa-5M-MTR',\n",
       " 'head_model': 'rigid',\n",
       " 'metric': 'mae',\n",
       " 'result': 0.333}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read(f\"{dataset_name}_{base_model}_ridge.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['caco2_wang',\n",
       " 'hia_hou',\n",
       " 'pgp_broccatelli',\n",
       " 'bioavailability_ma',\n",
       " 'lipophilicity_astrazeneca',\n",
       " 'solubility_aqsoldb',\n",
       " 'bbb_martins',\n",
       " 'ppbr_az',\n",
       " 'vdss_lombardo',\n",
       " 'cyp2d6_veith',\n",
       " 'cyp3a4_veith',\n",
       " 'cyp2c9_veith',\n",
       " 'cyp2d6_substrate_carbonmangels',\n",
       " 'cyp3a4_substrate_carbonmangels',\n",
       " 'cyp2c9_substrate_carbonmangels',\n",
       " 'half_life_obach',\n",
       " 'clearance_microsome_az',\n",
       " 'clearance_hepatocyte_az',\n",
       " 'herg',\n",
       " 'ames',\n",
       " 'dili',\n",
       " 'ld50_zhu']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = admet_group(path='data/')\n",
    "group.dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
