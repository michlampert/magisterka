{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from itertools import product\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import shelve\n",
    "import tqdm\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "from tdc.benchmark_group import admet_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from huggingmolecules import MatConfig, MatFeaturizer, MatModel\n",
    "from huggingmolecules import GroverConfig, GroverFeaturizer, GroverModel\n",
    "from huggingmolecules import RMatConfig, RMatFeaturizer, RMatModel\n",
    "from models import StrippedMatModel, StrippedGroverModel, StrippedRMatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import *\n",
    "from datasets import *\n",
    "from predict_procedure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mat import MolecularAttentionTransformer\n",
    "\n",
    "# model = MolecularAttentionTransformer()\n",
    "# model.predict([\"CN1CC[C@]23C(=O)C[C@@H]4C(=CCO[C@H]5CC(=O)N(c6ccccc62)[C@@H]3[C@@H]54)C1\"]) ## tooks 11m 4s (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group = admet_group(path = 'data/')\n",
    "# benchmark = group.get(\"CYP2D6_Substrate_CarbonMangels\")\n",
    "\n",
    "# dataset = benchmark[\"test\"]\n",
    "\n",
    "# print(dataset[dataset.Drug == \"CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C\"].to_markdown())\n",
    "\n",
    "# Output:\n",
    "# |     | smiles                             |   Y |\n",
    "# |----:|:-----------------------------------|----:|\n",
    "# |  58 | CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C |   1 |\n",
    "# | 226 | CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C |   0 |else 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "calculated = set(map(str, pathlib.Path(\"embeddings/\").glob(\"*/*.zip\")))\n",
    "\n",
    "pairs = product(get_dataset_names(), get_embedder_names())\n",
    "\n",
    "with open(\"embedding_params.txt\", \"w\") as f:\n",
    "    for dataset_name, model_name in pairs:\n",
    "        if f\"embeddings/{dataset_name}/{model_name}.zip\" not in calculated:\n",
    "            print(dataset_name, model_name, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "done = set(map(str, pathlib.Path(\"results/\").glob(\"*.pkl\")))\n",
    "\n",
    "pairs = product(get_dataset_names(), get_embedder_names())\n",
    "\n",
    "with open(\"predict_params.txt\", \"w\") as f:\n",
    "    for dataset_name, model_name in pairs:\n",
    "        if (f\"results/{dataset_name}_{model_name}_rigid.pkl\" not in done) or (f\"results/{dataset_name}_{model_name}_forest.pkl\" not in done):\n",
    "            print(dataset_name, model_name, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV, RidgeCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(df, split_idx, model, **kwargs):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    targets = list(filter(lambda col: col not in ['smiles', \"features\", 'embeddings', 'Drug_ID'], df.columns))\n",
    "\n",
    "    train_val = pd.concat([df.loc[split_idx[\"train\"]], df.loc[split_idx[\"valid\"]]])\n",
    "    train_val = train_val.fillna(train_val[targets].mode().iloc[0])\n",
    "\n",
    "    X = np.vstack(train_val.embeddings.to_numpy())\n",
    "    y = train_val[targets].to_numpy()\n",
    "\n",
    "    clf = model(kwargs).fit(scaler.fit_transform(X), y)\n",
    "\n",
    "    test = df.loc[split_idx[\"test\"]]\n",
    "    X = np.vstack(test.embeddings.to_numpy())\n",
    "\n",
    "    return clf.predict(scaler.transform(X))\n",
    "\n",
    "\n",
    "# predict_regression_lin = partial(predict_test, model=lambda kwargs: linear_model.LinearRegression())\n",
    "\n",
    "predict_regression_forest = partial(\n",
    "    predict_test,\n",
    "    model=lambda kwargs: GridSearchCV(\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            criterion=\"entropy\",\n",
    "            refit=True,\n",
    "            n_jobs=-1,\n",
    "            random_state=0,\n",
    "        ),\n",
    "        {\n",
    "            \"min_samples_split\": np.logspace(1, 5, 4, base=2).astype(int)\n",
    "        },\n",
    "        **kwargs\n",
    "    )\n",
    ")\n",
    "\n",
    "predict_regression_rigid = partial(\n",
    "    predict_test,\n",
    "    model=lambda kwargs: ClassifierChain(\n",
    "        RidgeCV(\n",
    "            alphas=np.logspace(-2, 2, 10),\n",
    "            cv=10,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# predict_classification_lin = partial(predict_test, model=lambda: ClassifierChain(LogisticRegression()))\n",
    "\n",
    "predict_classification_forest = partial(\n",
    "    predict_test,\n",
    "    model=lambda kwargs: ClassifierChain(GridSearchCV(\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            criterion=\"entropy\",\n",
    "            refit=True,\n",
    "            n_jobs=-1,\n",
    "            random_state=0,\n",
    "        ),\n",
    "        {\n",
    "            \"min_samples_split\": np.logspace(1, 5, 4, base=2).astype(int)\n",
    "        },\n",
    "        **kwargs\n",
    "    )))\n",
    "\n",
    "predict_classification_rigid = partial(\n",
    "    predict_test,\n",
    "    model=lambda kwargs: ClassifierChain(\n",
    "        RidgeClassifierCV(\n",
    "            alphas=np.logspace(-2, 2, 10),\n",
    "            cv=10,\n",
    "            penalty=\"l1\",\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Found local copy...\n",
      "Found local copy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('mae', 0.372)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name, base_model = \"Caco2_Wang\", \"ChemBERTa-5M-MTR\"\n",
    "\n",
    "_, split_idx = get_dataset(dataset_name)\n",
    "df = pd.read_pickle(f\"embeddings/{dataset_name}/{base_model}.zip\")\n",
    "\n",
    "preds = predict_regression_forest(df, split_idx, scoring=get_metric(dataset_name))\n",
    "preds\n",
    "\n",
    "evaluate(dataset_name, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(name):\n",
    "    with open(f\"results/{name}\", \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def spearmancorr_score(x, y):\n",
    "    rho, pval = spearmanr(x, y, axis=0)\n",
    "    return rho * (-1)\n",
    "\n",
    "\n",
    "def pr_auc_score(y_true, y_scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "\n",
    "def get_metric(dataset):\n",
    "    results = pd.DataFrame.from_records([read(name) for name in os.listdir(\"results/\")])\n",
    "    tmp1 = results.groupby(\"dataset\").first().reset_index()[[\"dataset\", \"metric\"]]\n",
    "    tmp2 = {\n",
    "        \"roc-auc\": \"roc_auc\",\n",
    "        \"rocauc\": \"roc_auc\",\n",
    "        \"pr-auc\": pr_auc,\n",
    "        \"mae\": \"neg_mean_absolute_error\",\n",
    "        \"rmse\": \"neg_root_mean_squared_log_error\",\n",
    "        \"spearman\": spearmancorr,\n",
    "        \"ap\": \"average_precision\",\n",
    "    }\n",
    "    return tmp2[dict(zip(tmp1.dataset, tmp1.metric))[dataset]]\n",
    "\n",
    "# get_metric(\"asd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Caco2_Wang'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "procedure(dataset_name, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'Caco2_Wang',\n",
       " 'base_model': 'ChemBERTa-5M-MTR',\n",
       " 'head_model': 'rigid',\n",
       " 'metric': 'mae',\n",
       " 'result': 0.333}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read(f\"{dataset_name}_{base_model}_rigid.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['caco2_wang',\n",
       " 'hia_hou',\n",
       " 'pgp_broccatelli',\n",
       " 'bioavailability_ma',\n",
       " 'lipophilicity_astrazeneca',\n",
       " 'solubility_aqsoldb',\n",
       " 'bbb_martins',\n",
       " 'ppbr_az',\n",
       " 'vdss_lombardo',\n",
       " 'cyp2d6_veith',\n",
       " 'cyp3a4_veith',\n",
       " 'cyp2c9_veith',\n",
       " 'cyp2d6_substrate_carbonmangels',\n",
       " 'cyp3a4_substrate_carbonmangels',\n",
       " 'cyp2c9_substrate_carbonmangels',\n",
       " 'half_life_obach',\n",
       " 'clearance_microsome_az',\n",
       " 'clearance_hepatocyte_az',\n",
       " 'herg',\n",
       " 'ames',\n",
       " 'dili',\n",
       " 'ld50_zhu']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = admet_group(path='data/')\n",
    "group.dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
