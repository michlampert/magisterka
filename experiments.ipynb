{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from itertools import product\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import shelve\n",
    "import tqdm\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michlampert/magisterka/venv/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "from tdc.benchmark_group import admet_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from huggingmolecules import MatConfig, MatFeaturizer, MatModel\n",
    "from huggingmolecules import GroverConfig, GroverFeaturizer, GroverModel\n",
    "from huggingmolecules import RMatConfig, RMatFeaturizer, RMatModel\n",
    "from models import StrippedMatModel, StrippedGroverModel, StrippedRMatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from utils import *\n",
    "from datasets import *\n",
    "import predict_procedure as pp\n",
    "import embedding_procedure as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mat import MolecularAttentionTransformer\n",
    "\n",
    "# model = MolecularAttentionTransformer()\n",
    "# model.predict([\"CN1CC[C@]23C(=O)C[C@@H]4C(=CCO[C@H]5CC(=O)N(c6ccccc62)[C@@H]3[C@@H]54)C1\"]) ## tooks 11m 4s (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group = admet_group(path = 'data/')\n",
    "# benchmark = group.get(\"CYP2D6_Substrate_CarbonMangels\")\n",
    "\n",
    "# dataset = benchmark[\"test\"]\n",
    "\n",
    "# print(dataset[dataset.Drug == \"CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C\"].to_markdown())\n",
    "\n",
    "# Output:\n",
    "# |     | smiles                             |   Y |\n",
    "# |----:|:-----------------------------------|----:|\n",
    "# |  58 | CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C |   1 |\n",
    "# | 226 | CCCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C |   0 |else 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "calculated = set(map(str, pathlib.Path(\"embeddings/\").glob(\"*/*.zip\")))\n",
    "\n",
    "pairs = product(get_dataset_names(), get_embedder_names())\n",
    "\n",
    "with open(\"embedding_params.txt\", \"w\") as f:\n",
    "    for dataset_name, model_name in pairs:\n",
    "        if f\"embeddings/{dataset_name}/{model_name}.zip\" not in calculated:\n",
    "            print(dataset_name, model_name, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "done = set(map(str, pathlib.Path(\"results/\").glob(\"*.pkl\")))\n",
    "\n",
    "pairs = list(product(get_regression_names(), [\"SELFormer\"]))\n",
    "calculated = list(map(lambda s: tuple(str(s).replace(\".\", \"/\").split(\"/\")[1:-1]), pathlib.Path(\"embeddings/\").glob(\"*/*.zip\")))\n",
    "\n",
    "params = list(product(list(set(pairs)), [\"forest\"]))\n",
    "\n",
    "\n",
    "with open(\"predict_params.txt\", \"w\") as f:\n",
    "    for (dataset_name, model_name), head_model in params:\n",
    "        if f\"results/{dataset_name}_{model_name}_{head_model}.pkl\" not in done:\n",
    "            print(dataset_name, model_name, head_model, file=f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "done = set(map(str, pathlib.Path(\"results/\").glob(\"*.pkl\")))\n",
    "\n",
    "pairs = list(product(get_dataset_names(), get_embedder_names()))\n",
    "calculated = list(map(lambda s: tuple(str(s).replace(\".\", \"/\").split(\"/\")[1:-1]), pathlib.Path(\"embeddings/\").glob(\"*/*.zip\")))\n",
    "\n",
    "params = list(product(list(set(pairs) & set(calculated)), [\"ridge\",\"forest\"]))\n",
    "\n",
    "\n",
    "with open(\"predict_params.txt\", \"w\") as f:\n",
    "    for (dataset_name, model_name), head_model in params:\n",
    "        if f\"results/{dataset_name}_{model_name}_{head_model}.pkl\" in done and dataset_name in get_classification_names():\n",
    "            print(dataset_name, model_name, head_model, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HIA_Hou with molbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Processing HIA_Hou with molbert\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HIA_Hou with molbert took 0.1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Processing HIA_Hou with molbert took 0.1m\n"
     ]
    }
   ],
   "source": [
    "dataset_name, model_name = \"HIA_Hou\", \"molbert\"\n",
    "\n",
    "df, _ = get_dataset(dataset_name)\n",
    "\n",
    "model = get_embedder(model_name)\n",
    "\n",
    "ep.procedure(dataset_name, df, model_name, model, max_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in get_dataset_names():\n",
    "    get_dataset(dataset_name)[0].reset_index()[[\"index\", \"smiles\"]].rename(columns={\"index\": \"chembl_id\", \"smiles\": \"canonical_smiles\"}).to_csv(f\"smiles_txt/{dataset_name}.txt\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in get_dataset_names():\n",
    "    os.system(f\"python SELFormer/generate_selfies.py --smiles_dataset=smiles_txt/{dataset_name}.txt --selfies_dataset=selfies/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"selformer_params.txt\", \"w\") as f:\n",
    "    for dataset_name in get_dataset_names():\n",
    "        if len(get_dataset(dataset_name)[0]) < 10000:\n",
    "            f.write(f\"{dataset_name}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sequence_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.2678825855255127, -0.04146221652626991, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.8832750916481018, -0.09156806021928787, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.2266165018081665, -0.035363443195819855, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1.1679654121398926, 0.12847484648227692, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[1.3297243118286133, 0.20555377006530762, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>662</td>\n",
       "      <td>[1.3313795328140259, -0.08630513399839401, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>663</td>\n",
       "      <td>[1.2012218236923218, 0.008925149217247963, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>664</td>\n",
       "      <td>[1.079952359199524, -0.17504577338695526, -0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>665</td>\n",
       "      <td>[1.0526909828186035, 0.13809537887573242, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>666</td>\n",
       "      <td>[1.0786561965942383, 0.05587581917643547, -0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>667 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                sequence_embeddings\n",
       "0        0  [1.2678825855255127, -0.04146221652626991, -0....\n",
       "1        1  [0.8832750916481018, -0.09156806021928787, -0....\n",
       "2        2  [1.2266165018081665, -0.035363443195819855, -0...\n",
       "3        3  [1.1679654121398926, 0.12847484648227692, -0.4...\n",
       "4        4  [1.3297243118286133, 0.20555377006530762, -0.3...\n",
       "..     ...                                                ...\n",
       "662    662  [1.3313795328140259, -0.08630513399839401, -0....\n",
       "663    663  [1.2012218236923218, 0.008925149217247963, -0....\n",
       "664    664  [1.079952359199524, -0.17504577338695526, -0.5...\n",
       "665    665  [1.0526909828186035, 0.13809537887573242, -0.4...\n",
       "666    666  [1.0786561965942383, 0.05587581917643547, -0.5...\n",
       "\n",
       "[667 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"selformer_embeddings/Half_Life_Obach.csv\").rename(columns={\"chembl_id\": \"index\"})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>smiles</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CCN1CC(CCN2CCOCC2)C(c2ccccc2)(c2ccccc2)C1=O</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>COC(=O)C1=C(C)NC(C)=C(C(=O)OCCN(C)Cc2ccccc2)C1...</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCN(CC)CCNC(=O)c1ccc(NC(C)=O)cc1</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CN1[C@H]2CC[C@@H]1C[C@H](OC(=O)C(CO)c1ccccc1)C2</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>O=c1[nH]cc(F)c(=O)[nH]1</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>662</td>\n",
       "      <td>CC(=O)Nc1c(I)c(NC(C)=O)c(I)c(C(=O)O)c1I</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>663</td>\n",
       "      <td>CN(C)CCc1c[nH]c2ccc(C[C@H]3COC(=O)N3)cc12</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>664</td>\n",
       "      <td>COc1ccc2cc1Oc1cc3c(cc1OC)CC[N+](C)(C)[C@H]3Cc1...</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>665</td>\n",
       "      <td>COc1cccc(C2(O)CCCCC2CN(C)C)c1</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>666</td>\n",
       "      <td>CN(C)CCc1c[nH]c2ccc(CS(=O)(=O)N3CCCC3)cc12</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>667 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                             smiles     Y\n",
       "0        0        CCN1CC(CCN2CCOCC2)C(c2ccccc2)(c2ccccc2)C1=O  4.10\n",
       "1        1  COC(=O)C1=C(C)NC(C)=C(C(=O)OCCN(C)Cc2ccccc2)C1...  4.10\n",
       "2        2                   CCN(CC)CCNC(=O)c1ccc(NC(C)=O)cc1  6.40\n",
       "3        3    CN1[C@H]2CC[C@@H]1C[C@H](OC(=O)C(CO)c1ccccc1)C2  4.10\n",
       "4        4                            O=c1[nH]cc(F)c(=O)[nH]1  0.12\n",
       "..     ...                                                ...   ...\n",
       "662    662            CC(=O)Nc1c(I)c(NC(C)=O)c(I)c(C(=O)O)c1I  1.80\n",
       "663    663          CN(C)CCc1c[nH]c2ccc(C[C@H]3COC(=O)N3)cc12  3.60\n",
       "664    664  COc1ccc2cc1Oc1cc3c(cc1OC)CC[N+](C)(C)[C@H]3Cc1...  5.10\n",
       "665    665                      COc1cccc(C2(O)CCCCC2CN(C)C)c1  5.80\n",
       "666    666         CN(C)CCc1c[nH]c2ccc(CS(=O)(=O)N3CCCC3)cc12  3.40\n",
       "\n",
       "[667 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = get_dataset(\"Half_Life_Obach\")[0].reset_index()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.join(b, on=\"index\", lsuffix=\"l\", rsuffix=\"r\").drop([\"indexl\", \"indexr\"], axis=1).rename(columns={\"sequence_embeddings\": \"embeddings\"})\n",
    "c[\"embeddings\"] = c[\"embeddings\"].map(eval)\n",
    "len(c.embeddings[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Featurizing datapoint 0\n"
     ]
    }
   ],
   "source": [
    "from deepchem.feat.graph_data import BatchGraphData\n",
    "from deepchem.feat.molecule_featurizers.conformer_featurizer import RDKitConformerFeaturizer\n",
    "from deepchem.models.torch_models.gnn3d import InfoMax3DModular\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "from deepchem.data.datasets import NumpyDataset\n",
    "\n",
    "smiles = [\"C[C@H](F)Cl\", \"C[C@@H](F)Cl\"]\n",
    "featurizer = RDKitConformerFeaturizer()\n",
    "data = featurizer.featurize(smiles)\n",
    "dataset = NumpyDataset(X=data)\n",
    "model = InfoMax3DModular(task='regression',\n",
    "                         hidden_dim=64,\n",
    "                         target_dim=10,\n",
    "                         aggregators=['max'],\n",
    "                         readout_aggregators=['mean'],\n",
    "                         scalers=['identity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"embeddings/Half_Life_Obach/mol2vec.zip\").embeddings.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
